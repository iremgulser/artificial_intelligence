{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55587c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Markov Decision Process model\n",
    "actions = (0,1)  # actions (0=left, 1=right)\n",
    "states = (1.0,1.25,1.5,1.75)  # states (tiles)\n",
    "rewards = [0.2,0.3,0.3,0.2]  # Direct rewards per state\n",
    "gamma = 0.9  # discount factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c5242ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition probabilities per state-action pair\n",
    "probs = [\n",
    "    [[0.9, 0.1], [0.1, 0.9], [0, 0], [0, 0], [0, 0]],\n",
    "    [[0.9, 0.1], [0, 0], [0.1, 0.9], [0, 0], [0, 0]],\n",
    "    [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0]],  # Terminating state (all probs 0)\n",
    "    [[0, 0], [0, 0], [0.9, 0.1], [0, 0], [0.1, 0.9]],\n",
    "    [[0, 0], [0, 0], [0, 0], [0.9, 0.1], [0.1, 0.9]],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f90614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iterations(S,A,P,R):\n",
    "    V={s: 0 for s in S}\n",
    "    optimal_policy= {s: 0 for s in S}\n",
    "    while True:\n",
    "        oldV=V.copy()\n",
    "        for s in S:\n",
    "            Q={}\n",
    "            for a in A:\n",
    "                Q[a]=R(s,a)+sum(P(s_next,s,a)* old_V[s_next]\n",
    "                               for s_next in S)\n",
    "                V[S]=max(Q.values())\n",
    "                optimal_policy[s] = max(Q, key=Q.get)\n",
    "                if all (old_V[s]==V(s) for s in S):\n",
    "                    break\n",
    "    return V, optimal_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5aac253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation (policy, S):\n",
    "    V = {s: 0 for s in S}\n",
    "    while True:\n",
    "        oldV = V. copy ()\n",
    "        if all (oldV[s] == V[s] for s in S):\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7595d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement (V, S, A):\n",
    "    policy = {s: A[0] for s in S}\n",
    "    for s in S:\n",
    "        Q = {}\n",
    "        for a in A:\n",
    "            Q[a] = R(s,a) + sum(P(s_next, s,a) * V[s_next]\n",
    "                                for s_next in S)\n",
    "            policy[s] = max(Q, key=Q.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3ab6e9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-af0240ab24ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mold_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_evaluation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_improvement\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-54773241fd9b>\u001b[0m in \u001b[0;36mpolicy_improvement\u001b[0;34m(V, S, A)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             Q[a] = R(s,a) + sum(P(s_next, s,a) * V[s_next]\n\u001b[0m\u001b[1;32m      7\u001b[0m                                 for s_next in S)\n\u001b[1;32m      8\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "def policy_iterations(S,A,P,R):\n",
    "    policy={s: A[0] for s in S}\n",
    "    while True:\n",
    "        old_policy=policy.copy()\n",
    "        V = policy_evaluation (policy, S)\n",
    "policy = policy_improvement (V, S, A)\n",
    "for s in S:\n",
    "    a = policy[s]\n",
    "    V[s] = R(s,a) + sum(P (s_next, s,a) * oldV[s_next]\n",
    "                        for s_next in S)\n",
    "    if all(old_policy[s] == policy[s] for s in S):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e370aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [*range (0, N+1)] # [0, 1, ...,N]\n",
    "A = [*range (0, N+1)] # [0, 1, ...,N]\n",
    "def P(s_next, s, a):\n",
    "    if s + a == s_next and a <= sum(s, N-s) and 0 < s < N: # win\n",
    "        return p\n",
    "    elif s - a == s_next and a <= sum(s, N-s) and 0 < s < N: # lose\n",
    "        return (1 - p)\n",
    "    else:\n",
    "        return 0\n",
    "    def R(s, a):\n",
    "        if s == N: # win\n",
    "            return 1 \n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "110293e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c49dbbdfa7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# max for M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimal_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "N= 100 # max for M\n",
    "p= 0.9 \n",
    "optimal_policy = policy_iterations(S,A,P,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d8bcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set value iteration parameters\n",
    "max_iter = 10000  # Maximum number of iterations\n",
    "delta = 1e-400  # Error tolerance\n",
    "V = [0, 0, 0, 0, 0]  # Initialize values\n",
    "pi = [None, None, None, None, None]  # Initialize policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1df416ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start value iteration\n",
    "for i in range(max_iter):\n",
    "    max_diff = 0  # Initialize max difference\n",
    "    V_new = [0, 0, 0, 0, 0]  # Initialize values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23a26250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#References:\n",
    "#   https://towardsdatascience.com/\n",
    "#   https://github.com/\n",
    "#   https://stackoverflow.com/\n",
    "#   https://www.kaggle.com/\n",
    "#   https://www.geeksforgeeks.org/\n",
    "#   https://medium.com/\n",
    "#   https://realpython.com/\n",
    "#   https://lightrun.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0c326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
